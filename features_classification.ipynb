{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification based on leaves features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing our own functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import src.Data as Data\n",
    "importlib.reload(Data)\n",
    "Data = Data.Data\n",
    "\n",
    "import src.Metrics as Metrics\n",
    "importlib.reload(Metrics)\n",
    "Metrics = Metrics.Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "`numpy` and `pandas` are used to manipulate the data\n",
    "\n",
    "`scikit-learn` is used to train the classification models and compute the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import LearningCurveDisplay, learning_curve, cross_validate, train_test_split, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(), \n",
    "    RandomForestClassifier(n_jobs=-1), \n",
    "    #BaggingClassifier(n_jobs=-1), \n",
    "    LogisticRegression(n_jobs=-1),\n",
    "    #SVC(),\n",
    "    #GaussianNB(),\n",
    "    #SGDClassifier(n_jobs=-1),\n",
    "    #KNeighborsClassifier(n_jobs=-1),\n",
    "    #GradientBoostingClassifier(),\n",
    "    #MLPClassifier(),\n",
    "    #AdaBoostClassifier()\n",
    "    \n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "The data is loaded from the `data` folder.\n",
    "\n",
    "Samples are split into a training set and a test set with a custom ratio. Stratified sampling is used to ensure that the proportion of samples in each class is the same in both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least populated class count: 8\n"
     ]
    }
   ],
   "source": [
    "data: Data = Data(test_size=0.2, include_images=False)\n",
    "\n",
    "least_populated_class_count = np.unique(data.y_train, return_counts=True)[1].min()\n",
    "print(\"Least populated class count:\", least_populated_class_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models\n",
    "\n",
    "#### _Without cross-validation_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We first train the models on the training set without cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit the model without cross-validation or hyperparameter tuning. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Fit the model without cross-validation or hyperparameter tuning. \\n')\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(data.x_train, data.y_train)\n",
    "    predictions = classifier.predict(data.x_test)\n",
    "\n",
    "    classifier_metrics = Metrics(classifier_name=classifier.__class__.__name__)\n",
    "    # Computing metrics\n",
    "    classifier_metrics.add_metric('accuracy_score', accuracy_score(data.y_test, predictions))\n",
    "    classifier_metrics.add_metric('f1_score', f1_score(data.y_test, predictions, average='macro'))\n",
    "    classifier_metrics.add_metric('precision_score', precision_score(data.y_test, predictions, average='macro'))\n",
    "    classifier_metrics.add_metric('recall_score', recall_score(data.y_test, predictions, average='macro'))\n",
    "\n",
    "    metrics_list.append(classifier_metrics)\n",
    "\n",
    "    Metrics.show_metrics_list(metrics_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
