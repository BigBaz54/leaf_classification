{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search\n",
    "This notebook is dedicated to hyperparameter search for the different classifiers that we chose to use for leaves classification base on the images.\n",
    "\n",
    "The goal is to find the best hyperparameters for each classifier using cross validation to compare the performances between the classifiers with the default hyperparameters and the classifiers with the best hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing our own functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T04:43:03.086504Z",
     "start_time": "2023-12-11T04:43:03.075484Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.Data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "`numpy` is used to manipulate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T04:43:03.094398Z",
     "start_time": "2023-12-11T04:43:03.079508Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "The data is loaded from the `data` folder.\n",
    "\n",
    "Samples are split into a training set and a test set with a custom ratio. Stratified sampling is used to ensure that the proportion of samples in each class is the same in both sets.\n",
    "\n",
    "The number of samples in the least represented class is computed to choose the number of folds for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T04:43:21.976400Z",
     "start_time": "2023-12-11T04:43:03.082897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least populated class count: 8\n",
      "This is the maximum valid number of folds for cross validation.\n"
     ]
    }
   ],
   "source": [
    "data: Data = Data(test_size=0.2, include_images=True)\n",
    "\n",
    "least_populated_class_count = np.unique(data.y_train, return_counts=True)[1].min()\n",
    "print(\"Least populated class count:\", least_populated_class_count)\n",
    "print(\"This is the maximum valid number of folds for cross validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the models\n",
    "Here you can choose which models you want to include in the hyperparameter search.\n",
    "\n",
    "The parameter `n_jobs` is used to specify the number of cores to use for parallel processing. If `-1` is given, all cores are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T04:43:22.046936Z",
     "start_time": "2023-12-11T04:43:21.975170Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "classifiers = [\n",
    "    RandomForestClassifier(n_jobs=-1),  # Time to fit < 5 hours. Results in report.\n",
    "    # SVC(),  # Unable to hyper thread. Too long to fit.\n",
    "    KNeighborsClassifier(n_jobs=-1),  # Time to fit < 5 hours. Results in report. \n",
    "    # GradientBoostingClassifier(),  # Unable to hyper thread. Too long to fit.\n",
    "    # AdaBoostClassifier()  # Unable to hyper thread. Too long to fit.\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the list of hyperparameters\n",
    "To simplify the hyperparameter search, we use the `get_params()` method of the classifier to get the list of hyperparameters that can be tuned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T04:43:22.051237Z",
     "start_time": "2023-12-11T04:43:22.047946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier: RandomForestClassifier\n",
      "Parameters:\n",
      "\t bootstrap\n",
      "\t ccp_alpha\n",
      "\t class_weight\n",
      "\t criterion\n",
      "\t max_depth\n",
      "\t max_features\n",
      "\t max_leaf_nodes\n",
      "\t max_samples\n",
      "\t min_impurity_decrease\n",
      "\t min_samples_leaf\n",
      "\t min_samples_split\n",
      "\t min_weight_fraction_leaf\n",
      "\t n_estimators\n",
      "\t n_jobs\n",
      "\t oob_score\n",
      "\t random_state\n",
      "\t verbose\n",
      "\t warm_start\n",
      "\n",
      "Classifier: KNeighborsClassifier\n",
      "Parameters:\n",
      "\t algorithm\n",
      "\t leaf_size\n",
      "\t metric\n",
      "\t metric_params\n",
      "\t n_jobs\n",
      "\t n_neighbors\n",
      "\t p\n",
      "\t weights\n"
     ]
    }
   ],
   "source": [
    "for classifier in classifiers:\n",
    "    print(\"Classifier:\", classifier.__class__.__name__)\n",
    "    print(\"Parameters:\")\n",
    "    for key in classifier.get_params():\n",
    "        print(\"\\t\", key)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosing the hyperparameters to tune\n",
    "We then need to choose from the list above which hyperparameters we want to tune. We can also choose the range of values to test for each hyperparameter.\n",
    "\n",
    "The `param_grid` variable is a dictionary where the keys are the names of the hyperparameters and the values are the list of values to test for each hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T04:43:22.055583Z",
     "start_time": "2023-12-11T04:43:22.054202Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grids = []\n",
    "\n",
    "# RandomForestClassifier\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 50, 100, 200, 500],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "if \"RandomForestClassifier\" in [classifier.__class__.__name__ for classifier in classifiers]:\n",
    "    param_grids.append(param_grid)\n",
    "\n",
    "# SVC\n",
    "param_grid = {\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"C\": [0.1, 0.5, 2, 5, 10, 20, 50, 100, 200, 500, 1000],\n",
    "    \"gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "if \"SVC\" in [classifier.__class__.__name__ for classifier in classifiers]:\n",
    "    param_grids.append(param_grid)\n",
    "\n",
    "# KNeighborsClassifier\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [1, 2, 5, 10],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "    \"leaf_size\": [1, 2, 5, 10, 20, 30, 50],\n",
    "    \"p\": [1, 2]\n",
    "}\n",
    "if \"KNeighborsClassifier\" in [classifier.__class__.__name__ for classifier in classifiers]:\n",
    "    param_grids.append(param_grid)\n",
    "\n",
    "# GradientBoostingClassifier\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.005, 0.01, 0.025, 0.05, 0.1, 0.5],\n",
    "    \"n_estimators\": [100, 500], \n",
    "    \"criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"max_depth\": [1, 2, 3, 5, 10],\n",
    "    \"min_samples_split\": [2, 5, 10, 15, 20],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]\n",
    "}\n",
    "if \"GradientBoostingClassifier\" in [classifier.__class__.__name__ for classifier in classifiers]:\n",
    "    param_grids.append(param_grid)\n",
    "\n",
    "# AdaBoostClassifier\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 200, 500],\n",
    "    \"learning_rate\": [0.001, 0.01, 0.1, 0.5],\n",
    "    \"algorithm\": [\"SAMME\", \"SAMME.R\"]\n",
    "}\n",
    "if \"AdaBoostClassifier\" in [classifier.__class__.__name__ for classifier in classifiers]:\n",
    "    param_grids.append(param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the models with all combinations of hyperparameters\n",
    "We use the `GridSearchCV` class to fit the models with all combinations of hyperparameters and find the best hyperparameters for each model. \n",
    "\n",
    "This class uses cross-validation to evaluate the performance through an exhaustive search over the hyperparameter values space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-11T04:46:15.345601Z",
     "start_time": "2023-12-11T04:43:22.057877Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "best_params = []\n",
    "best_scores = []\n",
    "\n",
    "for classifier, param_grid in zip(classifiers, param_grids):\n",
    "    print(\"Classifier:\", classifier.__class__.__name__)\n",
    "    print(\"Parameters:\")\n",
    "    for key in param_grid:\n",
    "        print(f\"\\t{key:12}: {param_grid[key]}\")\n",
    "    print(\"\")\n",
    "    \n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv=2, verbose=1, n_jobs=-1)\n",
    "    grid_search.fit(data.x_image_train, data.y_train)\n",
    "    best_params.append(grid_search.best_params_)\n",
    "    best_scores.append(grid_search.best_score_)\n",
    "    print(\"Best parameters:\", best_params[-1])\n",
    "    print(f\"Best score: {best_scores[-1]:.3f}\")\n",
    "    print(\"\\n###############################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-11T04:46:15.345035Z"
    }
   },
   "outputs": [],
   "source": [
    "for classifier, best_param, best_scores in zip(classifiers, best_params, best_scores):\n",
    "    print(\"Classifier:\", classifier.__class__.__name__)\n",
    "    print(\"Best parameters:\")\n",
    "    for key in best_param:\n",
    "        print(f\"\\t{key:12}: {best_param[key]}\")\n",
    "    print(f\"Best score: {best_scores:.3f}\")\n",
    "    print(\"\\n###############################\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
